{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0887959-1e39-4e58-b2e6-c71117fac7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "words = (open('names.txt','r')).read().splitlines()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1de2abe-5554-4e0f-84d0-820ea55f2afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5a4b02-f405-4fbf-9a31-6c19c85e7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5, 13], [5, 13, 13]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "def get(s):\n",
    "    return (ord(s) - ord('a')) + 1\n",
    "\n",
    "for word in words[:5000]:\n",
    "    for i in range(len(word)):\n",
    "        now = [0, 0, 0]\n",
    "        now1 = 0\n",
    "        now[1] = get(word[i])\n",
    "        if(i - 1 >= 0):\n",
    "            now[0] = get(word[i-1])\n",
    "        if(i + 1 < len(word)):\n",
    "            now[2] = get(word[i+1])\n",
    "        if(i + 2 < len(word)):\n",
    "            now1 = get(word[i+2])\n",
    "        X.append(now)\n",
    "        Y.append(now1)\n",
    "\n",
    "print(X[:2])\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7168d20-2666-47cb-88cf-eb4e83ce2aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uff, we have the dataset, now we make preparations\n",
    "g = torch.Generator().manual_seed(69*420)\n",
    "C = torch.randn((27,2),generator=g,requires_grad=True) # this is the lookup table\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f520f324-ddf9-48a2-8dc4-08f1dd83d65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30245, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to prepare it for processing by the hidden layer\n",
    "# so we need to....?\n",
    "# we need to linearise the data C[X] so that it is easier to play with\n",
    "# we convert [36,3,2] to [36,6] by just putting all three things linearly \n",
    "N = C[X].view(len(C[X]),-1)\n",
    "N.shape\n",
    "\n",
    "# I guess that's what was needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121a02f5-68f8-4a04-8e20-4a04aee2fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30245, 6])\n",
      "torch.Size([6, 100])\n",
      "tensor([[-0.5084,  0.9821,  0.9948,  ...,  0.8410,  0.9050, -0.9690],\n",
      "        [ 0.3706, -0.5361,  0.9033,  ...,  0.3452,  0.9829, -0.9952],\n",
      "        [-0.6352, -0.2983,  0.3272,  ...,  0.9990, -0.8990, -0.2820],\n",
      "        ...,\n",
      "        [ 0.1594,  0.9991,  0.9997,  ...,  0.9507, -0.3358,  0.4034],\n",
      "        [-0.8576, -0.9966, -0.9219,  ...,  0.3815,  0.9307, -0.9903],\n",
      "        [-0.2601,  0.9964,  0.9745,  ...,  1.0000, -0.9962,  0.9380]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# The hidden layer just does a tanh and sends it forward to the softmax\n",
    "W1 = torch.randn((6,100),generator=g,requires_grad=True)\n",
    "B1 = torch.randn(100,generator=g,requires_grad=True)\n",
    "\n",
    "print(N.shape)\n",
    "print(W1.shape)\n",
    "N = torch.tanh(N@W1 + B1)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bf8979-97a8-432f-bda5-95938e209bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30245, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ce89dcd-a371-49b7-a65c-c6ed57ce990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4689e-10, 1.2802e-04, 2.3130e-05,  ..., 4.5349e-01, 3.2673e-04,\n",
       "         5.0097e-07],\n",
       "        [7.6284e-10, 1.0355e-02, 2.0179e-02,  ..., 6.5103e-01, 2.4623e-04,\n",
       "         2.7340e-08],\n",
       "        [4.6093e-05, 3.9172e-06, 9.9161e-01,  ..., 1.0914e-10, 3.8243e-05,\n",
       "         3.6075e-08],\n",
       "        ...,\n",
       "        [9.1791e-20, 4.2661e-15, 5.2792e-14,  ..., 2.4819e-11, 7.4604e-09,\n",
       "         4.8854e-11],\n",
       "        [1.5666e-04, 5.5538e-04, 9.5496e-01,  ..., 2.3724e-06, 1.0518e-07,\n",
       "         3.2143e-10],\n",
       "        [2.5987e-09, 3.1352e-10, 2.1052e-01,  ..., 5.0436e-13, 1.6967e-05,\n",
       "         7.4473e-08]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax layer, we get [36,100] from last layer\n",
    "# we must return a single layer of size 26 with the probabilities of all chars\n",
    "W2 = torch.randn((100,27),generator=g,requires_grad=True) \n",
    "B2 = torch.randn(27,generator=g,requires_grad=True)\n",
    "\n",
    "logits = N@W2 + B2\n",
    "counts = logits.exp() # remove the negative logits\n",
    "probs = counts / counts.sum(1,keepdims=True)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c1aebf-1ade-41d7-af37-358684ae9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have the final probabilities for each input?, oh wait, its all random right now, we need to train it\n",
    "# but how do \n",
    "# the idea is: with a neural network, we are just processing the probabilities, we get what we put in\n",
    "# its totally random right now, but I need to train it\n",
    "# but how do I get the output of the things I put in ?\n",
    "# we have already put in the things that we need to find the probablities of\n",
    "# how th find em ?\n",
    "# the things is, we need to find the log likelihood of the expected ouputs with a given input\n",
    "# and we just have to optimize for that\n",
    "# okayyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b589637-93b6-4c39-b5ef-5c5ae291c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.7108, grad_fn=<NegBackward0>)\n",
      "15.71077823638916\n",
      "13.766487121582031\n",
      "12.104907989501953\n",
      "10.970582008361816\n",
      "10.166509628295898\n",
      "9.567642211914062\n",
      "9.118239402770996\n",
      "8.741822242736816\n",
      "8.404030799865723\n",
      "8.09371280670166\n",
      "7.8078107833862305\n",
      "7.54425048828125\n",
      "7.301305294036865\n",
      "7.078368663787842\n",
      "6.875195503234863\n",
      "6.690739154815674\n",
      "6.522704601287842\n"
     ]
    }
   ],
   "source": [
    "def get_loss(probs):\n",
    "    likelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        pro = probs[i, Y[i]]\n",
    "        likelihood += torch.log(pro)\n",
    "    likelihood /= len(X)\n",
    "    loss = -likelihood\n",
    "    return loss\n",
    "\n",
    "# Function to reset gradients\n",
    "def reset_grads():\n",
    "    if W1.grad is not None:\n",
    "        W1.grad.zero_()\n",
    "    if W2.grad is not None:\n",
    "        W2.grad.zero_()\n",
    "    if B1.grad is not None:\n",
    "        B1.grad.zero_()\n",
    "    if B2.grad is not None:\n",
    "        B2.grad.zero_()\n",
    "    if C.grad is not None:\n",
    "        C.grad.zero_()\n",
    "\n",
    "# Function to perform gradient descent step\n",
    "def gradient_descent():\n",
    "    learning_rate = 0.1\n",
    "    W1.data -= learning_rate * W1.grad\n",
    "    W2.data -= learning_rate * W2.grad\n",
    "    B1.data -= learning_rate * B1.grad\n",
    "    B2.data -= learning_rate * B2.grad\n",
    "    C.data -= learning_rate * C.grad\n",
    "\n",
    "# Function to update probabilities\n",
    "def update_probs():\n",
    "    global N\n",
    "    global logits\n",
    "    global counts\n",
    "    global probs\n",
    "    N = C[X].view(len(C[X]), -1)\n",
    "    N = torch.tanh(N @ W1 + B1)\n",
    "    logits = N @ W2 + B2\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    return probs\n",
    "\n",
    "# Initialize `probs` before the loop\n",
    "probs = update_probs()\n",
    "\n",
    "# Print initial loss\n",
    "print(get_loss(probs))\n",
    "\n",
    "# Training loop\n",
    "for descent in range(30):\n",
    "    # Compute loss\n",
    "    loss = get_loss(probs)\n",
    "    \n",
    "    # Reset gradients\n",
    "    reset_grads()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Gradient descent step\n",
    "    gradient_descent()\n",
    "    \n",
    "    # Recalculate everything with the updated parameters\n",
    "    probs = update_probs()\n",
    "\n",
    "    # Print the loss\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddb3b6-4673-469a-bd6a-533ae000794e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
